Techniques for, e.g., avoiding indexed-offset addressing on the 8080
====================================================================

Reading the 8080 instruction set and watching David Givens’s recorded
livestream of [writing a text editor for CP/Mish][0], I’m struck by
the nonexistence of indexed-offset addressing modes, and the
relatively large cost of emulating them; so I was thinking about ways
to avoid this cost.

[0]: http://cowlark.com/2019-06-28-cpm-vi/

8080 indexed-offset memory access
---------------------------------

If your program wants to access a one-byte variable the C compiler has
allocated at offset 4 from the stack pointer in its stack frame, it
needs to do something like the following:

        LXI H, 4     ; HL := 4; 10 cycles
        DAD SP       ; HL += SP; 10 cycles
        MOV B, M     ; B := M[HL]; 7 cycles

This takes 27 clock cycles, which is 13.5 μs at the 8080’s 2MHz
maximum clock speed.  In some cases, the MOV at the end might be
replaced with something like `INR M` to increment the variable (10
cycles, 5 more than incrementing a register) or `ADD M` to add it to
the accumulator without loading it into a register first (7 cycles, 3
more than adding a register).  So you could reasonably argue that the
cost is something like 23 cycles rather than 27.

(I haven’t looked at the actual code generated by ACK or BDS C, and
I’m not that familiar with 8080 assembly language, so I might have
gotten something wrong here.)

The code is pretty much the same if you’re indexing a record† rather
than a stack frame, just that the base address doesn’t come from SP:

        LXI H, 4
        DAD B        ; or D
        MOV B, M

And it’s almost the same if you’re indexing into an array (without
bounds-checking), except that you might need to multiply the index by
the array-item size; for fetching the first 8 bits of a 16-bit item,
for example:

        LXI H, 2834H ; the array base address
        DAD B
        DAD B        ; an extra 10 cycles
        MOV B, M

By contrast, if the variable is at a fixed location in memory, you can
avoid the `DAD` bit, cutting the cost from 27 or 23 cycles to 17 or
13, depending on how you figure it:

        LXI H, 2082H ; HL := 0x2082; 10 cycles
        MOV B, M     ; B := M[HL]; 7 cycles

The same principle applies if the variable is at some fixed offset in
a struct pointed to by DE or BC; you just `DAD` the relevant register
pair to the offset in HL.

Chasing pointers involves loading 16-bit values; the LHLD and SHLD
instructions (16 cycles each) load and store the value of HL at fixed
addresses.  Loading it from an address pointed to by a register is
more involved; you can load it one byte at a time, for a total of 23
cycles (if you want the result to be in HL and not, say, DE).  For an
apples-to-apples comparison with the 8-bit situation, it’s 43 cycles
if we first point HL at an offset into the stack frame:

        LXI H, 4     ; 10 cycles
        DAD SP       ; 10 cycles

        MOV E, M     ; E := M[HL]; 7 cycles
        INX H        ; HL++; 5 cycles
        MOV D, M     ; D := M[HL]; 7 cycles
        XCHG         ; HL, DE := DE, HL; 4 cycles

Or you can use SP as a pointer and then `POP H`, taking 10 cycles.
Pointing the stack pointer at a random address with `SPHL` only takes
5 cycles, but that probably requires you to save the stack pointer
ahead of time so you can restore it later.  Unfortunately, I think the
only way to access the old value of SP is with `DAD SP`, so the whole
sequence is gnarly and takes 52 cycles:

        XCHG         ; HL, DE := DE, HL; 4 cycles (save old HL)
        LXI H, 0     ; HL := 0; 10 cycles
        DAD SP       ; HL += SP; 10 cycles
        XCHG         ; HL, DE := DE, HL; 4 cycles (save old SP)

        SPHL         ; SP := HL; 5 cycles
        POP H        ; HL := M[SP]; SP += 2; 10 cycles

        XCHG         ; HL, DE := DE, HL; 4 cycles (restore old SP)
        SPHL         ; SP := HL; 5 cycles

But the `SPHL`, `POP H` sequence in the middle is only 15 cycles, so
if you need to follow a chain of pointers, that’s probably a faster
way to do it.  However, in the middle of this mess, you don't have
access to the old stack pointer, which would further complicate access
to local variables allocated in the stack frame.

Finally, you could use self-modifying code, which takes 32
cycles — slower and more code than just doing byte-at-a-time access,
but doesn't trash DE:

        SHLD $+4     ; store HL into the address field of next insn; 16 cycles
        LHLD 0       ; load HL from address to be inserted; 16 cycles

This has the potential advantage that the two instructions can be at
separated places, and in particular you might be able to set the
address once and load from it many times.

> For some special cases, there were faster ways to access data on the
> stack, the most obvious being simply by popping it, but there were
> others.  For example, Alan Miller’s _8080/Z80 Assembly Language:
> Techniques for Improved Programming_ suggests that if you have passed
> an argument to a subroutine on the stack:
> 
>         PUSH B        ; i.e., BC
>         CALL FOO      ; i.e., PUSH PC and then JMP
> 
> Then that subroutine best can get the argument (inconveniently hidden
> beneath its return address) into a register using `XTHL` (p. 38):
> 
>     FOO POP H         ; i.e., HL; 10 cycles
>         XTHL          ; M[SP], HL := HL, M[SP]; 18 cycles
> 
> This also works for return values.

In summary, on the 8080, it’s dramatically faster to load data from
memory at statically allocated addresses than at addresses on the
stack or in records or arrays:

<table>
<tr><th>address <th>bits <th>cycles to read into register <th>bytes of code
<tr><td>static <td>8 <td>17                               <td>4
<tr><td>in HL <td>8 <td>7                                 <td>1
<tr><td>offset from SP, BC, or DE <td>8 <td>27            <td>5
<tr><td>static <td>16 <td>16                              <td>3
<tr><td>in HL  <td>16 <td>23                              <td>4
<tr><td>offset from SP, BC or DE <td>16 <td>43            <td>8
</table>

The first CP/M machines used the 8080, but the backwards-compatible
Z80 was the CPU most CP/M machines used.  It had index registers IX
and IY which apparently ameliorated these problems noticeably, but did
not remove them entirely.  I haven’t tried these exercises on the Z80.

† A record is called a “struct” in C-derived languages, a “tuple” in
ML-derived languages, and an “object” in Smalltalk-derived languages.

### Dynamic scoping with shallow binding in LISP ###

Many other old computers had similar problems, and I think this is the
reason for the conventional wisdom among 1970s LISP implementors that,
although lexical scoping was a good idea in theory and simplified the
understanding of programs, in practice, the performance cost was too
high, relative to then-conventional dynamic scoping with shallow
binding, in which the current value of each variable was stored in a
fixed memory location, but upon entering and exiting a subroutine that
has it as a local variable, its previous value is pushed onto a stack,
then restored upon exit.

Similar considerations, plus the then-popular technique of storing
subroutine return addresses in the return instruction through
self-modifying code rather than using a stack, prompted the omission
of recursion from COBOL and older versions of FORTRAN.

`static` variables in C
-----------------------

At one point (about 45' into the livestream, I think), Givens gets a
noticeable speedup in redrawing his screen by changing a couple of
16-bit stack-allocated variables (`auto`, the default storage class in
C) to the `static` storage class, thus enabling the use of 
static-address instruction sequences like those above rather than
(presumably) the offset-from-SP sequences.

At first, this optimization introduced a bug, since local `static`
variables are initialized upon the first entry to the subroutine,
while `auto` variables with initializers are initialized upon every
entry.

You could imagine an optimizing source-to-source translation that
would simply add a `static` to every implicitly `auto` local variable
in your program and separate its initialization into a separate
statement.  This transformation would be sound — it would not break
previously correct code — except in the case of recursive functions,
or more specifically variables in recursive functions whose values are
read after at least one recursive call without being written to again
first.

This translation improves things, but it has a few problems.  First,
you can’t declare function parameters `static` in C.  Second, it could
result in your program using more memory than before, because while
previously you only needed enough space, on the stack, for the
functions in the single deepest call chain (weighted by activation
record size), now you need enough memory for all the activation
records to be alive at once, because functions can no longer share
memory with other functions that aren’t active concurrently.  Third,
access to variables in recursive functions is still slow.

Compile-time stack allocation
-----------------------------

We could imagine instead statically allocating the activation records
of a nonrecursive program on a sort of stack, at compile-time.  You
could allocate the activation record of `main` at some address
`local_variable_start`, and all other activation records at one more
than the greatest address used by any of their callers’ activation
records.  This allocates a single static address to every local
variable.

So, for example, given call chains main[6] -> a[3] -> b[5] -> c[2] and
a -> d[7] -> c, where the number in brackets is the number of bytes
needed for each activation record, you would allocate main at 0, a at
6, b and d each at 9, and c at 16.  b and d overwrite the same memory,
but that’s okay because they’re never running at the same time.  When
b calls c, two bytes are left unused, but that’s also okay, because c
isn’t getting its local variables’ addresses from b; they’re compiled
into it.

To extend this to recursive programs, we can break each recursive
loop, or potential recursive loop, by introducing a “trampoline”
function into it at some point; a greedy approach may not be optimal
but is likely adequate.  The “trampoline” has the job of saving the
variables from the functions participating in the recursive loop onto
a run-time stack somewhere, then forwarding the call to the next
function in the recursive loop, then restoring the saved variables
when it returns.  There may be some variables that don’t need to be
saved because their saved values are statically never used after the
recursive call.  It may be worthwhile as an optimization to simply
`memcpy()` a relevant chunk of the compile-time stack rather than
enumerating all the necessary variables.

C, however, has another feature that complicates this: you can take
the address of a local variable and pass it to other functions.  (In
C, you can also store it in data structures; the Pascal family
including Oberon (see file `oberon` and file
`imgui-programming-language`) instead provides a “var parameter”
mechanism analogous to downward funargs, which, however, poses
precisely the same potential problem for this mechanism.)  It is
expected that such an address will remain valid until the function
it’s in returns, despite possible recursion.  If such a variable
occurs in a recursive loop, it needs to be immediately allocated on a
run-time stack, rather than being initially located at a static
address and possibly saved and restored later.

For calls via function pointers, the function pointer type, rather
than a specific function, can be a node in the call graph which
“calls” all the functions whose addresses are taken and coerced to
that pointer type.  More conservatively, we could consider all
function pointers to be a single node in the call graph.

This approach thus gives us the full semantics of C or Oberon at a
much lower run-time cost on machines like the 8080.  However, it
requires whole-program analysis to precisely calculate which functions
potentially participate in a recursive loop, and that might pose some
difficulties for self-hosted development.

You could pretty much solve this problem with a linker, though.  Each
reference to an in-memory statically-allocated local variable gets
relocated by the function’s activation-record base address, and the
linker is responsible for assigning those base addresses at link time
and fixing up the relocations, as well as inserting trampolines, which
would probably have to copy entire activation records rather than just
the “live” parts.  Probably you also have to runtime-stack-allocate
every variable whose address gets taken, too, and you need to expose
function-pointer types to the linker.

This is a nontraditional sort of linker, and it has to do more
relocations than the usual kind, but it seems like it still ought to
enable fairly powerful self-hosted development with separate
compilation, because the object files should be about the same size as
before.

Context switching with “buffer-local variables”
-----------------------------------------------

Multics Emacs was the first Emacs to be scriptable in Lisp, during the
1970s period I mentioned above.  In Emacs, there are a lot of
frequently-accessed variables that are local, not to a function call,
but to a particular editor buffer; if you open two files at once, for
example, you probably want to maintain independent cursor positions in
them.  The modern approach to doing this is to store all those
variables in a record, allocate a record for each buffer, and maintain
a pointer to the “current buffer” record, and associate a buffer
pointer with each open window on the screen.  Switching buffers is
achieved by changing the value of the current-buffer pointer.  This
requires, as explained above, indexed-offset addressing to all these
variables.

To avoid this extra cost, Multics Emacs used an approach similar to
shallow binding: all the variables for the *current buffer* are stored
in constant places in memory, and when you switch buffers, those
variables are copied into the record for the old buffer, then copied
out of the record for the new buffer.  The rationale for this was that
accessing things like the current cursor position is so much more
frequent than switching buffers that it doesn’t make sense to slow
down access to the cursor position in order to speed up switching
buffers.

(I suspect GNU Emacs uses the same mechanism even today, but I haven’t
looked.)

This principle is applicable to many kinds of records that enjoy a
certain sort of locality of reference.  It’s common for a program to
do a number of things to one file before switching to doing things to
another file, for example, and many GUI programs, if they even use
more than a single window at all, do many things in sequence to the
same window.  Image-processing programs frequently do many things in
sequence to the same image, parsers frequently do many things in
sequence to the same input stream, network programs frequently do many
things in sequence to the same network socket, and database programs
frequently do many things in sequence to the same table or cursor.

Such programs can probably work better on an 8080 by using the
copy-in/copy-out approach used by Multics Emacs for its buffer-local
variables.  They may even be able to do this as an optimization — for
example, your file access functions could take a file-number argument,
maintaining the “current file” state entirely internal, but checking
that argument against the current file number upon entry.

However, there are other uses of records that do not work as well in
this approach.  Pretty much anything that repeatedly walks a tree or
linked list of the same kind of records is going to be slower rather
than faster this way, including abstract syntax trees and database
query plan execution.

Avoiding 16-bit variables
-------------------------

The 8080 has some limited 16-bit ALU operations; as noted above, it
can do 16-bit addition, fetch, and store, but it can also do 16-bit
increment and decrement.  However, these operations are much slower
than the 8-bit variety, and its 8-bit repertoire also includes
subtraction, addition and subtraction with carries and borrows, bit
rotations, and bitwise AND, OR, XOR, and NOT.