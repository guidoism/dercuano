I thought it would be interesting to explore multitouch interfaces for
livecoding music.  Here are some ideas:

- On a cellphone, you can expand your working area by using the phone
  accelerometers (and gyros, if available) to rotate the phone to move
  around a larger virtual space.
- Quasimodal interface elements pop up during a touch and then permit
  continuous adjustment in one or more dimensions with one or more
  touches — the same or different touches.
- Waveform and spectrum displays at different scales can elucidate
  what is happening in a single node.
- Individually reified signal inputs might offer a quasimodal action
  to overwrite them with some existing signal.
