Approaches to failure-free, bounded-space, and bounded-time programming
=======================================================================

Often, the most convenient way to program a piece of software is to
use garbage collection, recursion, and the Lisp object-graph memory
model they were born in, often along with closures and dynamic typing.
But these approaches have their drawbacks: almost any part of your
program can fail or require unbounded time to execute.  Sometimes it
is useful to write programs that will not fail, even on a computer
with finite memory, and will make progress in bounded time.

The basic incompatibilities are the following:

- In the object-graph memory model, heap allocation happens often,
  usually implicitly (although not in early versions of Java), can
  always fail, and can almost always take an unbounded amount of time.
- Closures in particular — at least, the way they are normally
  implemented — give rise to implicit heap allocation.
- Recursive function calls can potentially use both unbounded space
  (for the stack) and unbounded time.  If you have no recursion and no
  closures, you don’t strictly need a stack; it’s purely an
  optimization.
- With dynamic typing, any primitive operation — and, in OO languages,
  any method call — can fail due to a type error.

Here I will discuss approaches that can be used to write programs that
can execute in bounded time, bounded space, and without the
possibility of error conditions arising.

These approaches are usually used in contexts where system resources
are very limited, and so they are usually used in conjunction with a
lot of optimization, which can reduce both the average-case resource
use and the worst-case resource use of the program.  However, they are
conceptually distinct from optimization, even though they may be
confused with it.

Static checking, including type checking
----------------------------------------

The most general technique is to check invariants before the program
is run.  An invariant that is (correctly) verified to hold by static
reasoning cannot be violated give rise to a run-time error.  For
example, object-oriented programs in languages such as OCaml are
guaranteed not to compile a method call on an object that might not
support that method.  This is almost true in C++, but C++ has enough
undefined behavior that it is in practice impossible to make any
compile-time assertions about program behavior.

Such static checking can happen after compile time as well as before.
For example, for TinyOS, a stack depth checker was developed that
statically verifies the maximum stack depth of a machine-code program.
(See also file `direct-addressing` for more on how to do this.)

Pointer-reversal tree traversal
-------------------------------

Lisp systems traditionally used a mark-and-sweep garbage collector,
which first *marks* all the nodes in memory that are accessible from
“roots” (such as the stack or global variables), then *sweeps* through
memory to find any unmarked objects, adding them to the free list.  A
simple implementation of the mark phase that handles only conses might
look something like this:

    (defun gc-mark (node)
      (when (and (consp node)
                 (not (eq (mark-field node) *collection-number*)))
        (setf (mark-field node) *collection-number*)
        (gc-mark (car node))
        (gc-mark (cdr node))))

This is simple enough, but it sweeps a critical issue under the
carpet: those recursive calls to `mark` eat up stack space.  How much
stack space do they need?  Well, it can be as much as one level of
stack for every live cons, if they’re all in a single list!  Normally
traversing a tree through recursive calls like this is a reasonable
thing to do, but this function is being invoked because the
interpreter ran out of memory, except what it needs for the stack, and
needs to free some up.  So statically bounding the stack usage, as
mentioned in the previous item, would be really super useful.

You might think we could rewrite it into a non-recursive loop:

    (defun gc-mark (node)
      (loop while (and (consp node)
                  (not (eq (mark-field node) *collection-number*)))
         do (setf (mark-field node) *collection-number*)
         do (gc-mark (car node))
         do (setf node (cdr node))))

That way, if we have one huge long list `(a b c d ... zzz)`, we don’t
eat up our stack recursing down it; each cons of the list gets
processed in the same stack frame as the previous one.  But we still
have a recursive loop which can still eat up space bounded only by the
number of conses — it’s just that now it has to look like
`(((((...zzz...)))))` instead.

The fundamental problem is that every time we encounter a new cons, we
encounter not one but two new pointers to follow, and so whichever
path we choose to take, the number of paths not traveled by can always
keep growing, one new path for each cons node we traverse.

If we could only leave some sort of breadcrumbs in those conses in
order to avoid needing to allocate that data on the stack!  Too bad
they’re already full of essential data.

Consider this implementation of NREVERSE for lists:

    (defun my-nreverse (list)
      (loop with next with reversed = nil
         if (null list) return reversed
         do (progn
              (setf next (cdr list))
              (setf (cdr list) reversed)
              (setf reversed list)
              (setf list next))))

It isn’t recursive and doesn’t allocate any memory other than its
three local variables.  Nevertheless, `(nreverse (nreverse list))`
will traverse the same list nodes twice, once forwards and once
backwards, and it leaves them in the same state as before.  By
reversing the pointers, it maintains the state it needs to traverse
the list again in reverse order.

This implementation of NREVERSE is a simple case of pointer-reversal
tree traversal.  Where regular tree traversal maintains a single
pointer to the current node, we maintain two pointers: the current
node and the previous node.  (While executing a movement along the
tree, we have an additional temporary pointer, called `next` above.)
The previous node used to have a pointer to the current node, but no
longer does; it now points to its own previous node instead.  It
happens that the backward traversal in this case is precisely the same
as the forward traversal, but that is not the case in general.

To walk the whole tree, sometimes you’ll be descending down the left
branch (the car) and sometimes down the right branch (the cdr).  That
means that sometimes the previous node will have its car reversed and
pointing to its parent, in which case when we return back up to it we
want to descend down the cdr branch instead, and sometimes it will
have its cdr reversed and pointing to its parent, in which case when
we return back up to it we want to keep on returning back up to its
parent.  To distinguish these two cases, we need to store that one bit
of per-node state somewhere, just like the mark bit, and typically we
use a bit somewhere in the node itself, though there are other
options.  If you have three or four children on a node, you need two
bits instead of one, and so on.  When you finish walking the tree, you
have undone all your mutations.

And that’s Deutsch–Schorr–Waite tree traversal, which needs only a bit
per node in the worst case instead of a word per node.

Deutsch–Schorr–Waite tree traversal is designed as a failure-free
algorithm because, like most algorithms, garbage collection can only
fail by running out of memory; but, in the GC case, that failure is an
overwhelmingly likely outcome if you don’t make it impossible.

You can use it for things other than garbage collection.  You can
implement a binary-tree search function using Deutsch–Schorr–Waite
traversal, for example; you just choose which child to recurse down by
comparing the key, and when you’re traversing back up the tree, you
always just go up to the parent, rather than sometimes traversing down
to another child, as you do for garbage collection.  More
interestingly, you can implement red-black tree insertion this way.

Using it for DAG traversal may be hairier; GC uses the mark bit to
avoid endlessly revisiting the same nodes, but other traversal
algorithms may not be able to.

An interesting thing about this traversal is that it’s achieved by
using mutation instead of the usual side-effect-free algorithms to
traverse the tree, because the alternative to storing the breadcrumbs
with mutation is to allocate memory for them, and that introduces
failure.  (See file `z-machine-ops` for some notes on a memory model
that’s all about tree mutation and was at one point used by a
significant number of hackers.)

Of course, such a mutating tree traversal would be a disaster if it
could be interrupted in the middle, for example, by an out-of-memory
exception or a program interruption from the keyboard.  But since what
we’re exploring here is precisely how to eliminate such exceptions
from our system, we are justified in taking advantage of the benefits
thus gained.

Note that, in the above loop, the number of pointers to a given node
remains constant, except for the ephemeral copy in `next`.  I think
this is a necessary property of all such traversal algorithms on
trees, which is to say, data structures with only a single pointer to
each node; my reasoning is as follows.

If the reference count of such a linearly-referenced node drops, it
drops to zero, and the node leaks.  If you have a garbage collector,
it may recover the node later, and you may be able to avoid turning a
memory leak into an actual failure, but for reasons explained in the
introduction, I don’t think garbage collection is likely to be
compatible with failure-free computing.

For the reference count of such a linearly-referenced node to
increase, either it must be overwriting some other reference and
decreasing its reference count, or it must be allocating new memory;
neither of these is compatible with failure-free computing.

(The potential hole in this reasoning is that it’s legitimate for the
traversal algorithm to have some finite number of local variables like
`next` above that potentially alias pointers found in nodes on the
heap, but which may be the only access path to a node at some time.
I’m not sure this is ever essential but I don’t have a strong argument
that it isn’t.)

Swap is an adequate primitive for expressing such arbitrary
permutations of pointers, and it guarantees that no pointers are
duplicated or destroyed.  The pointer permutation in the above
NREVERSE loop could be thus expressed without temporary variables as
follows:

    (swapf reversed (cdr list))
    (swapf list reversed)

However, I do not have faith that such a microscopic approach to
eliminating failure can scale to a whole computing system.

Note that this approach to tree traversal does not bound the time
needed for a tree traversal, only the space, and indeed it prevents
you from killing the traversal process after a timeout to bound the
traversal time cheaply.

Fixed-size queues to permit communication with non-failure-free systems
-----------------------------------------------------------------------

It’s quite common for a computer system to contain some parts that
have to be failure-free and use bounded space and bounded time, and
other parts that don’t; for example, a robot control system might
contain one component that periodically toggles a pin to generate a
waveform to control a servomotor, another component monitoring sensors
and running a PID control algorithm that commands the first component
what signal to emit, and a third motion-planning component that tells
the PID control what set-point to use.  If the waveform generator
misses its deadlines (a few hundred μs of error at most is acceptable;
RC model servos use a 50Hz pulse-position-modulation signal with a
pulse width of 500μs to 2500μs encoding the commanded position, so
100μs of error is a 5% error), the waveform will have the wrong duty
cycle, and the servomotor will receive the wrong command, possibly
breaking the robot or a person near it.  If the PID control algorithm
misses its deadlines (typically a few milliseconds), the control
system will at least oscillate and possibly go out of control.  If the
motion-planning algorithm runs slowly, though, the robot just takes
longer to get things done.

This gives you a lot of freedom to have failures and missed deadlines
in your motion-planning algorithm, but not if they can propagate to
the waveform generator or even the PID controller.  But clearly these
components of the system need to communicate somehow.

The simplest approach is for them to share an atomically-updated
variable; in an analog system, this might be the voltage on a wire
connecting two of the components, or if we’re running the PID
controller on the same microcontroller that generates the waveform, a
`volatile` variable written to by the PID controller process and read
by an interrupt handler that generates the waveform, or an I/O
register in a waveform-generation peripheral integrated into the
microcontroller, like the AVR’s timer/counter modules.

In the case of a `volatile` variable, though, we need to be careful of
the danger of “torn reads”: perhaps you’re updating the value from
0x00ff to 0x0100, but on an AVR, that update involves sequentially
setting two different bytes of RAM.  If an interrupt handler runs
between the two updates, it might see 0x0000 or 0x01ff and the robot
might kill somebody.

(The “variable” might be arbitrarily large; you can think of
framebuffers as being such “variables” shared between the main program
and the display hardware, or in the case of the Arduino TVout library,
the interrupt handler that generates the video signal.  In this case
“tearing” is manifested as on-screen “tearing” of images.)

This is similar to the CRT ADC case for which Gray invented Gray code,
and so in this case you could try using Gray code to limit the
magnitude of the torn-read error, but there are other more general
solutions.  One is to use a circular buffer to enqueue values to be
communicated between components with different deadlines, a fixed-size
queue that never blocks, in order to isolate failures within a given
component.

XXX include implementation

This allows the PID component, for example, to isolate itself from
failures in motion planning — if it goes to read messages from motion
planning and none are there, it immediately gets a queue-empty
message, a totally normal situation, and goes on about its business.
Similarly, the waveform generator, if it has no new messages from the
PID component, can go on about its business; and if there are
interrupt handlers for the sensors feeding the PID controller, they
too can add messages to a queue for it, not concerned about the PID
controller’s lack of adherence to their deadlines.  If the queue gets
full because the PID controller is failing, the sensor-reading
messages will be lost, but the sensor-reading interrupt handler won’t
itself fail.

The same approach is essential in non-isochronous communication
networks.  If a gateway receives packets on one or more input streams
whose maximum total input bandwidth is A, and forwards those packets
to one or more network interfaces whose total minimum guaranteed
output bandwidth is B, then as long as A > B, it needs a bounded-size
queue for outbound packets, and may drop packets at times.  (Most
commonly B = 0 because the common types of networks do not provide any
guaranteed bandwidth.)

Fixed-size object pools
-----------------------

Anytime algorithms
------------------

“Anytime algorithms” or “interruptible algorithms” are a family of
algorithms which can be interrupted at any time and get some kind of
answer; if allowed to run longer, they can produce better answers.  In
particular, iterative approximation algorithms, which produce a series
of progressively closer approximations to a mathematically correct
answer, can be used as anytime algorithms.

For example, this Python implementation of the method of secants (from
file `implementation-separation`) is an anytime algorithm.  It tries
to find a zero of the scalar function `f` starting from guesses `x0`
and `x1`, which are in general vectors:

    def sec_seq(f, x0, x1):
        y = f(x0), f(x1)

        while True:
            yield x1
            x0, x1 = x1, x1 - y[1]*(x1 - x0)/(y[1] - y[0])
            y = y[1], f(x1)

After each iteration, `sec_seq` yields control back to the main
program along with its current best solution; the main program can
elect to resume it for another iteration or to accept that solution,
either because it’s adequately precise, because it’s run out of time,
or perhaps because a different approach to finding a zero is working
better.  (CPython doesn’t allow us to prove tight bounds on the
execution time of a single iteration, or to interrupt it either safely
or in bounded time, but you could imagine a language that did; and, in
some cases, even CPython’s loosey-goosey behavior will be good
enough.)

Anytime algorithms can exist in non-continuous domains, too — an
optimizing compiler, for example, could reasonably work by
constructing a correct but possibly slow compiled piece of code, then
attempt various ways of optimizing it as long as there is time.

Mathematical optimization
-------------------------
Moving things in linked lists
-----------------------------
Constant-space representations
------------------------------
The object-embedding memory model
---------------------------------

The object-embedding memory model eliminates certain failure modes
from the object-graph memory model.  In its pure form, all allocation
is static, so there is no chance of any allocation failure.  Embedded
objects cannot be NULL and cannot be of the wrong type.

Interval arithmetic?
--------------------
Arena allocators
----------------

If you allocate memory from an arena (or “region”, in MLKit’s term, or
“pool”, in the terminology of the Apache APR library) that is all
freed at once, you get constant-time allocation and constant-time
deallocation.  To eliminate failure and bound time and space usage,
you then must merely prove a worst-case bound on the allocation of the
program, and allocate a bigger arena than that.

Functional iteration/concurrency
--------------------------------
Hard priority scheduling
------------------------
Wait-free synchronization
-------------------------

Handling concurrency with locks or monitors introduces unwanted
coupling between the time bounds of different processes: the
worst-case execution time of code in a high-priority thread that needs
to enter a monitor must include the time it needs to wait on whatever
other thread might currently hold that monitor, which is to say, all
code that can execute inside that monitor in any thread.  Priority
inversion, where a thread holding a lock that is blocking a
high-priority thread has to sleep while an intermediate-priority
thread runs, is perhaps the most severe manifestation of this problem,
but it is more general.

Interrupt handlers never use locks, because there is no mechanism to
put the interrupt handler to sleep until the main program releases the
lock, then wake it back up again.